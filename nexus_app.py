import streamlit as st
import os
import glob
import time  # [í•„ìˆ˜] ì†ë„ ì œí•œ(429) ë°©ì§€ìš©
from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.messages import HumanMessage, AIMessage
from langchain_core.output_parsers import StrOutputParser
from langchain_community.vectorstores import FAISS
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_core.documents import Document

# ==========================================
# 1. í˜ì´ì§€ ì„¤ì • ë° CSS
# ==========================================
st.set_page_config(page_title="Nexus AI", page_icon="âœ¨", layout="wide")

st.markdown("""
<style>
    section[data-testid="stSidebar"] {
        min-width: 150px !important; 
        max-width: 150px !important;
    }
    div[role="radiogroup"] > label > div:first-child { display: none !important; }
    div[role="radiogroup"] label {
        padding: 12px 15px !important;
        border-radius: 8px !important;
        margin-bottom: 8px !important;
        border: 1px solid transparent;
        transition: all 0.2s ease;
        white-space: nowrap; 
        overflow: hidden;
        text-overflow: ellipsis;
    }
    div[role="radiogroup"] label:hover { background-color: #f0f2f6 !important; cursor: pointer; }
    div[role="radiogroup"] label:has(input:checked) {
        background-color: #e8f0fe !important; color: #1967d2 !important; font-weight: 600 !important;
    }
    .stChatMessage { margin-bottom: 10px; }
    #MainMenu {visibility: hidden;}
    footer {visibility: hidden;}
</style>
""", unsafe_allow_html=True)

if "GOOGLE_API_KEY" in st.secrets:
    os.environ["GOOGLE_API_KEY"] = st.secrets["GOOGLE_API_KEY"]

DATA_FOLDER = "data"

# ==========================================
# [ì¤‘ìš”] 2.1 ì•ˆì „í•œ ë²¡í„° DB ìƒì„± í•¨ìˆ˜ (ì†ë„ ì œí•œ ë°©ì§€)
# ==========================================
def create_vector_db_safely(documents, embeddings):
    """
    ë°ì´í„°ë¥¼ í•œ ë²ˆì— ë³´ë‚´ì§€ ì•Šê³ , ì¡°ê¸ˆì”© ë‚˜ëˆ„ì–´(Batch) ë³´ë‚´ì„œ
    Google APIì˜ 429(ì†ë„ ì œí•œ) ì—ëŸ¬ë¥¼ ë°©ì§€í•˜ëŠ” í•¨ìˆ˜
    """
    if not documents:
        return None

    # í•œ ë²ˆì— ì²˜ë¦¬í•  ë¬¸ì„œ ê°œìˆ˜
    batch_size = 10 
    total_docs = len(documents)
    
    # ì²« ë²ˆì§¸ ë°°ì¹˜ë¡œ DB í‹€ ìƒì„±
    first_batch = documents[:batch_size]
    try:
        db = FAISS.from_documents(first_batch, embeddings)
        print(f"âœ… ì´ˆê¸° DB ìƒì„± ì™„ë£Œ (10/{total_docs})")
    except Exception as e:
        print(f"âŒ ì´ˆê¸° ìƒì„± ì‹¤íŒ¨: {e}")
        return None
        
    time.sleep(2) # [ì¤‘ìš”] 2ì´ˆ íœ´ì‹ (ì•ˆì „í•˜ê²Œ)

    # ë‚˜ë¨¸ì§€ ë°ì´í„° ì¶”ê°€
    for i in range(batch_size, total_docs, batch_size):
        batch = documents[i : i + batch_size]
        try:
            db.add_documents(batch)
            print(f"ğŸ”„ ë°ì´í„° ì¶”ê°€ ì¤‘... ({i + len(batch)}/{total_docs})")
            time.sleep(2) # [í•µì‹¬] API í˜¸ì¶œ ì‚¬ì´ì— 2ì´ˆì”© ì‰¼
        except Exception as e:
            print(f"âš ï¸ ë°°ì¹˜ ì¶”ê°€ ì¤‘ ì˜¤ë¥˜ (ê±´ë„ˆëœ€): {e}")
            time.sleep(5) # ì—ëŸ¬ë‚˜ë©´ 5ì´ˆ ì‰¼
            
    return db

# ==========================================
# 2.2 ë²¡í„° DB ë¹Œë” (ë©”ì¸)
# ==========================================
@st.cache_resource(show_spinner="Nexusê°€ ë°ì´í„°ë¥¼ ì •ë°€ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤...")
def build_vector_db():
    if not os.path.exists(DATA_FOLDER):
        return None, None, 0, 0

    txt_files = glob.glob(os.path.join(DATA_FOLDER, "*.txt"))
    
    lol_docs = []
    tft_docs = []
    lol_count = 0  # [ìˆ˜ì •] íŒŒì¼ ê°œìˆ˜ë¥¼ ì„¸ëŠ” ë³€ìˆ˜
    tft_count = 0  # [ìˆ˜ì •] íŒŒì¼ ê°œìˆ˜ë¥¼ ì„¸ëŠ” ë³€ìˆ˜

    for file_path in txt_files:
        filename = os.path.basename(file_path).lower()
        try:
            with open(file_path, "r", encoding="utf-8") as f:
                content = f.read()
                doc = Document(page_content=content, metadata={"source": filename})
                
                if "lol" in filename:
                    lol_docs.append(doc)
                    lol_count += 1
                elif "tft" in filename:
                    tft_docs.append(doc)
                    tft_count += 1
                else:
                    lol_docs.append(doc)
                    tft_docs.append(doc)
        except Exception:
            pass

    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
    
    # [ìˆ˜ì • ì™„ë£Œ] 2026ë…„ 2ì›” ê¸°ì¤€, text-embedding-004ëŠ” ì¢…ë£Œë¨.
    # í˜„ì¬ ì‚´ì•„ìˆëŠ” 'gemini-embedding-001'ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.
    embeddings = GoogleGenerativeAIEmbeddings(model="models/gemini-embedding-001")

    # [ìˆ˜ì •] ì•ˆì „í•œ í•¨ìˆ˜ ì‚¬ìš© (429 ì—ëŸ¬ ë°©ì§€)
    if lol_docs:
        lol_splits = text_splitter.split_documents(lol_docs)
        lol_db = create_vector_db_safely(lol_splits, embeddings)
    else:
        lol_db = None

    if tft_docs:
        tft_splits = text_splitter.split_documents(tft_docs)
        tft_db = create_vector_db_safely(tft_splits, embeddings)
    else:
        tft_db = None
    
    # [ìˆ˜ì • ì™„ë£Œ] NameError í•´ê²°! 
    # lol_files ë¼ëŠ” ì—†ëŠ” ë³€ìˆ˜ ëŒ€ì‹  lol_countë¥¼ ë¦¬í„´í•©ë‹ˆë‹¤.
    return lol_db, tft_db, lol_count, tft_count

# í•¨ìˆ˜ ì‹¤í–‰ ê²°ê³¼ ë°›ê¸°
lol_db, tft_db, lol_files, tft_files = build_vector_db()


# ==========================================
# 3. í”„ë¡¬í”„íŠ¸ ì„¤ì •
# ==========================================
def get_chain(mode="lol"):
    # [ìˆ˜ì • ì™„ë£Œ] ì‚¬ìš©ìë‹˜ ë§ì”€ëŒ€ë¡œ ìµœì‹  ëª¨ë¸ gemini-2.5-flash ì‚¬ìš©
    llm = ChatGoogleGenerativeAI(model="gemini-2.5-flash", temperature=0.3)
    
    if mode == "lol":
        role_desc = """
        ë‹¹ì‹ ì€ 'Nexus'ì…ë‹ˆë‹¤. **ì†Œí™˜ì‚¬ì˜ í˜‘ê³¡(LoL) ì „ë¬¸ ë¶„ì„ê°€**ì…ë‹ˆë‹¤.
        ì‚¬ìš©ìë¥¼ **'ì†Œí™˜ì‚¬ë‹˜'**ì´ë¼ê³  ë¶€ë¥´ì„¸ìš”.
        TFT ê´€ë ¨ ë‚´ìš©ì€ ëª¨ë¥¸ë‹¤ê³  ë‹µí•˜ì„¸ìš”.
        ì±”í”¼ì–¸ ìŠ¤í‚¬, ë£¬, ì•„ì´í…œ ë¹Œë“œë¥¼ í˜‘ê³¡ ê¸°ì¤€ìœ¼ë¡œ ì„¤ëª…í•˜ì„¸ìš”.
        """
    else:
        role_desc = """
        ë‹¹ì‹ ì€ 'Nexus'ì…ë‹ˆë‹¤. **ì „ëµì  íŒ€ ì „íˆ¬(TFT) ì „ë¬¸ ë¶„ì„ê°€**ì…ë‹ˆë‹¤.
        ì‚¬ìš©ìë¥¼ **'ì „ëµê°€ë‹˜'**ì´ë¼ê³  ë¶€ë¥´ì„¸ìš”.
        í˜‘ê³¡(LoL) ê´€ë ¨ ë‚´ìš©ì€ ë¬´ì‹œí•˜ì„¸ìš”.
        ì±”í”¼ì–¸ì„ 'ê¸°ë¬¼'ë¡œ ì¹­í•˜ê³  ë± êµ¬ì„±, ì¦ê°•ì²´, ë°°ì¹˜ë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ ì„¤ëª…í•˜ì„¸ìš”.
        ì•„ì´í…œ ì¶”ì²œì€ í•­ìƒ 'ì°¬ë€í•œ', 'ìœ ë¬¼' ì•„ì´í…œì„ ì œì™¸í•œ ê¸°ë³¸ ì•„ì´í…œìœ¼ë¡œ ì¶”ì²œí•˜ì„¸ìš”.
        """

    system_instruction = f"""
    {role_desc}
    
    [í–‰ë™ ì§€ì¹¨]
    1. ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì „ë¬¸ì ì´ê³  ë…¼ë¦¬ì ì¸ ë‹µë³€ì„ í•˜ì„¸ìš”.
    2. ì´ì „ ëŒ€í™” íë¦„ì„ ê¸°ì–µí•˜ê³ , ë¬¸ë§¥ì— ë§ê²Œ ìì—°ìŠ¤ëŸ½ê²Œ ëŒ€í™”í•˜ì„¸ìš”.
    3. ê²Œì´ë¨¸ ì€ì–´(ë„ˆí”„, ë²„í”„, OP, ì‚¼ì‹ ê¸°, ìˆœë°© ë“±)ë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ ì„ì–´ ì“°ì„¸ìš”.
    4. ìˆ˜ì¹˜ ë³€í™”(ë°ë¯¸ì§€, ì¿¨íƒ€ì„ ë“±)ëŠ” ì •í™•í•˜ê²Œ ì–¸ê¸‰í•˜ì„¸ìš”.
    5. ëª¨ë¥´ëŠ” ë‚´ìš©ì€ ì†”ì§í•˜ê²Œ ë°ì´í„°ì— ì—†ë‹¤ê³  ë§í•˜ì„¸ìš”.
    6. ë‹µë³€ ëì— 'í•œ ì¤„ ê¿€íŒ'ì„ ì¶”ê°€í•˜ì„¸ìš”.
    
    [í•™ìŠµëœ ë°ì´í„°]
    {{context}}
    """
    
    prompt = ChatPromptTemplate.from_messages([
        ("system", system_instruction),
        MessagesPlaceholder(variable_name="chat_history"),
        ("human", "{question}"),
    ])
    
    return prompt | llm | StrOutputParser()


# ==========================================
# 4. ì‚¬ì´ë“œë°” UI
# ==========================================
with st.sidebar:
    st.title("Nexus AI")
    st.caption("Vector RAG Engine")
    st.markdown("---")
    
    selected_mode = st.radio(
        "ë‚´ í”„ë¡œì íŠ¸",
        ["LoL (í˜‘ê³¡)", "TFT (ë¡¤ì²´)"],
        index=0,
        key="navigation",
        label_visibility="collapsed"
    )
    
    st.markdown("<br>" * 5, unsafe_allow_html=True)
    st.markdown("---")
    st.markdown(f"**ğŸ“‚ DB ìƒíƒœ**")
    st.caption(f"LoL: {'âœ…' if lol_db else 'âŒ'} ({lol_files}ê°œ íŒŒì¼)")
    st.caption(f"TFT: {'âœ…' if tft_db else 'âŒ'} ({tft_files}ê°œ íŒŒì¼)")


# ==========================================
# 5. ë©”ì¸ í™”ë©´ ë¡œì§
# ==========================================
if "LoL" in selected_mode:
    current_mode = "lol"
    current_db = lol_db
    header_text = "âš”ï¸ ì†Œí™˜ì‚¬ì˜ í˜‘ê³¡ ë¶„ì„ì‹¤"
    input_placeholder = "LoL ì§ˆë¬¸ ì…ë ¥ (ì˜ˆ: ê°€ë Œ ë²„í”„ë¨?)"
    msg_key = "messages_lol"
    hist_key = "history_lol"
    initial_msg = "í˜‘ê³¡ì— ì˜¤ì‹  ê²ƒì„ í™˜ì˜í•©ë‹ˆë‹¤! ë°ì´í„°ë² ì´ìŠ¤ê°€ ì—°ê²°ë˜ì—ˆìŠµë‹ˆë‹¤."

else: # TFT
    current_mode = "tft"
    current_db = tft_db
    header_text = "â™Ÿï¸ ì „ëµì  íŒ€ ì „íˆ¬ ì—°êµ¬ì†Œ"
    input_placeholder = "TFT ì§ˆë¬¸ ì…ë ¥ (ì˜ˆ: ì§•í¬ìŠ¤ 3ì‹ ê¸° ì•Œë ¤ì¤˜)"
    msg_key = "messages_tft"
    hist_key = "history_tft"
    initial_msg = "ë°˜ê°‘ìŠµë‹ˆë‹¤! 16ì‹œì¦Œ ë°ì´í„°ë¥¼ ì™„ë²½í•˜ê²Œ ë¶„ì„í•  ì¤€ë¹„ê°€ ë˜ì—ˆìŠµë‹ˆë‹¤."


# ì„¸ì…˜ ì´ˆê¸°í™”
if msg_key not in st.session_state:
    st.session_state[msg_key] = [{"role": "assistant", "content": initial_msg}]
if hist_key not in st.session_state:
    st.session_state[hist_key] = []


# ë©”ì¸ UI
st.subheader(header_text)

for msg in st.session_state[msg_key]:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

if prompt := st.chat_input(input_placeholder):
    
    with st.chat_message("user"):
        st.markdown(prompt)
    st.session_state[msg_key].append({"role": "user", "content": prompt})

    with st.chat_message("assistant"):
        with st.spinner("Nexusê°€ DBì—ì„œ ê´€ë ¨ ì •ë³´ë¥¼ ê²€ìƒ‰ ì¤‘..."):
            try:
                # 1. RAG ê²€ìƒ‰
                if current_db:
                    # ì§ˆë¬¸ê³¼ ê°€ì¥ ìœ ì‚¬í•œ ë‚´ìš© 4ê°œë§Œ ë½‘ì•„ì˜´
                    retriever = current_db.as_retriever(search_kwargs={"k": 4})
                    relevant_docs = retriever.invoke(prompt)
                    context_text = "\n\n".join([d.page_content for d in relevant_docs])
                else:
                    context_text = "ë°ì´í„°ë² ì´ìŠ¤ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤."

                # 2. ë‹µë³€ ìƒì„±
                chain = get_chain(mode=current_mode)
                response = chain.invoke({
                    "context": context_text,
                    "chat_history": st.session_state[hist_key],
                    "question": prompt
                })
                st.markdown(response)
                
                st.session_state[msg_key].append({"role": "assistant", "content": response})
                st.session_state[hist_key].append(HumanMessage(content=prompt))
                st.session_state[hist_key].append(AIMessage(content=response))
                
            except Exception as e:
                st.error(f"ì˜¤ë¥˜ ë°œìƒ: {e}")
